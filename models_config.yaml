models:
  # ========== LOCAL MODELS (Ollama) ==========
  # - name: "llama3.1-8b"
  #   provider: "ollama"
  #   endpoint_url: "http://localhost:11434/api/generate"
  #   model_id: "llamma3.1:8b"

  #  - name: "gemma3-27b"
  #   provider: "ollama"
  #  endpoint_url: "http://localhost:11434/api/generate"
  # model_id: "gemma3:27b"

  # - name: "qwen3-14b"
  #  provider: "ollama"
  #  endpoint_url: "http://localhost:11434/api/generate"
  #  model_id: "qwen3:14b"

  # - name: "deepseek-r1-14b"
  #  provider: "ollama"
  #  endpoint_url: "http://localhost:11434/api/generate"
  #  model_id: "deepseek-r1:14b"

  # ========== CLOUD MODELS ==========
  - name: "gpt-5"
    provider: "openai"
    api_key_env: "OPENAI_API_KEY"
    model_id: "gpt-5"

  #- name: "llama-3.3-70b-groq"
  #  provider: "groq"
  #  api_key_env: "GROQ_API_KEY"
  #  model_id: "llama-3.3-70b-versatile"

  - name: "gemini-3.0-pro"
    provider: "google"
    api_key_env: "GOOGLE_API_KEY"
    model_id: "gemini-3-pro-preview"
